---
title: "Movie Ratings"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(ggplot2)
library(knitr)
library(readr)
library(resample)
library(stringr)
```

# Sobre o arquivo
O datasaet aqui utilizado é uma coleção de avaliações do tipo 5 estrelas e sistema de tags livres. Os dados são do sistema de recomendação MovieLens. Ele contém no total 105,339 mil avaliações e 6,138 tags num total de 10,329 filmes. As informações foram geradas por 668 usuários entre 03 de Abril de 1996 e 09 de Janeiro de 2016. O arquivo final deste dataset foi gerado no dia 11 de Janeiro de 2016.

Este dataset é apenas uma amostra dos dados reais. Os usuários foram selecionados aleatóriamente. Todos os usuários selecionados tinham ao menos 20 avaliações feitas. Nenhuma informação outra que um id para identificar o usuário individualmente no dataset foram dadas.

# Questões para Inferência
1. Escolha uma trilogia (ou uma n-logia com n > 3) e avalie para qual dos episódios da trilogia há melhor avaliação e para qual há mais variação nas notas atribuídas ao filme. (Exemplos: Poderoso Chefão, Star Wars, Matrix, etc.)
2. Normalmente os filmes têm vários gêneros. Existe uma relação entre em quantos gêneros os filmes se encaixam e a avaliação que os filmes recebem? Mais especificamente: se consideramos a os filmes com 1, 2, 3 ... gêneros, existe alguma quantidade de gêneros num mesmo filme que em geral recebe avaliações melhores? Caso exista, estime a diferença entre essa combinação e filmes com apenas um gênero. (Repare que você terá que escolher que medida você comparará: média, mediana, etc.)

```{r message=FALSE}
movies = read_csv("data/movies.csv")
links = read_csv("data/links.csv")
ratings = read_csv("data/ratings.csv")
tags = read_csv("data/tags.csv")

movies = movies %>%
  mutate(n_genres = str_count(genres, "\\|") + 1)

movies_ratings = movies %>%
  left_join(ratings, by = c("movieId" = "movieId"))
```

### Escolha uma trilogia
A trilogia escolhida foi Toy Story, franquia que teve seu primeiro filme lançado em 1995. Este foi o primeiro filme animação lançado pela Pixar, e teve um grande público.

Para esta análise o filme foi escolhido por ter uma quantidade significante de avaliações por filme, como visto abaixo.

```{r}
toy_story = movies_ratings %>%
  filter(grepl("Toy Story", title))

toy_story_by_movie = toy_story %>%
  group_by(title) %>%
  summarise(number_of_ratings = n(),
            mean = mean(rating),
            median = median(rating),
            standard_deviation = sd(rating))

kable(toy_story_by_movie)
```

```{r fig.width=10}
toy_story_bar = ggplot(toy_story, aes(x = rating, group = title)) + geom_bar() + facet_wrap(~ title) + theme_bw()

toy_story_bar.vlinedata = toy_story %>%
  group_by(title) %>%
  summarise(rating_mean = mean(rating), rating_median = median(rating))

toy_story_bar +
  geom_vline(aes(xintercept=rating_mean), 
                           toy_story_bar.vlinedata, color="red") +
  geom_vline(aes(xintercept=rating_median), 
                           toy_story_bar.vlinedata, color="blue") +
  ylab("Ocorrência") +
  xlab("Avaliação")
```
<center>
<span style="color:blue">Azul</span> é para a mediana e <span style="color:red">Vermelho</span> apra a média 
</center>


A distribuição das avaliações se mostra bem equilibrada. Tanto a média quando a mediana parecem estar bem próximas uma da outra. Por este motivo e por eu concordar que a opinião de cada usuário deva ter um impacto na avaliação geral do filme, eu escolhi a média. A mediana tem uma valor mais forte com relação a variação dos valores na amostra, entretanto isso significaria que um usuário não teria um impacto tão significativo na avaliação total do filme.

Para responder a primeira questão, utilizaremos o bootstrap como ferramenta para encontrar um intervalo de confiança para a população baseado na amostra que temos.

#### Para qual filme da trilogia há melhor avaliação?
Como a média foi escolhida para representar a avaliação geral, uma inferência em cima dessa medida foi feita. O processo de bootstrap para gerar o intervalo de confiança para a avaliação geral da população foi baseado no trabalho feito por [nazareno](https://github.com/nazareno/ciencia-de-dados-1/tree/master/4-Inferencia).

O intervalo com confiança de 95% é mostrado abaixo
```{r fig.width=10}
bstrap_rating = function(toy, id, r, name, statistic, probs) {
  rating = filter(toy, movieId == id)$rating
  
  b = bootstrap(rating, statistic, R = r,
              statisticNames = name)
  ci = CI.bca(b, probs = probs)
  
  return(ci)
}

chart_ics = function(df, medidas, title) {
  df %>% 
    ggplot(aes(x = medidas, ymin = X2.5., ymax = X97.5.)) + 
    geom_errorbar(width = .2) +
    theme_minimal() +
    ggtitle(title) +
    xlab("Intervalos de Confiança")
}

probs = c(0.025, 0.975)
r = 10000
mean = base::mean

t1 = bstrap_rating(toy_story, 1, r, "Toy Story (1995)", mean, probs)
t2 = bstrap_rating(toy_story,  3114, r, "Toy Story 2 (1999)", mean, probs)
t3 = bstrap_rating(toy_story, 78499, r, "Toy Story 3 (2010)", mean, probs)
df = data.frame(rbind(t1, t2, t3))

chart_ics(df, row.names(df), "IC das Avaliações dos Filmes")
```

Como os intervalos de confiança se sobrepõe, não é possível afirmar diretamente qual o filme que teve a melhor avaliação apenas olhando para os itnervalos de confiança separadamente, eles existe significância nas estatísticas.

#### Para qual filme as avaliações variam mais?

No caso da variação entre as avaliações, calculamos o desvio padrão entre estas avaliações e a média, nesse caso obtemos um IC da forma:
```{r fig.width=10}
t1 = bstrap_rating(toy_story, 1, r, "Toy Story (1995)", sd, probs)
t2 = bstrap_rating(toy_story, 3114, r, "Toy Story 2 (1999)", sd, probs)
t3 = bstrap_rating(toy_story, 78499, r, "Toy Story 3 (2010)", sd, probs)
df = data.frame(rbind(t1, t2, t3))

chart_ics(df, row.names(df), "IC da Variação das Avaliações dos Filmes")
```

O mesmo acontece com a variação entre as avaliações. Como os I.Cs para Toy Story e Toy Story 2 estão dentro do intervalo de Toy Story 3, todos os três desvios padrões podem ser o mesmo.

Um dos fatores de o I.C do Toy Story 3 ter um intervalo maior que os demais, deve-se a quantidade de amostras que temos para este filme.

Para responder a segunda pergunta, Existe uma relação entre em quantos gêneros os filmes se encaixam e a avaliação que os filmes recebem? Fazemos parecido ao primeiro, mas desta vez focando na quantidade de gêneros por filme

```{r}
movies_ratings %>%
  group_by(n_genres) %>%
  summarize(Filmes = n()) %>%
  select("Número de Gêneros" = n_genres, Filmes) %>%
  kable()
```

Analisando a quantidade de filmes em cada categoria decidi por apenas considerar as categorias que tenham mais que 100 filmes

```{r fig.width=10}
bstrap_rating_by_genre = function(movies_, n_genre, r, name, statistic, probs) {
  rating = filter(movies_, n_genres == n_genre, !is.na(rating))$rating
  
  b = bootstrap(rating, statistic, R = r,
              statisticNames = name)
  ci = CI.bca(b, probs = probs)
  
  return(ci)
}

genres = movies_ratings %>%
  group_by(n_genres) %>%
  summarise(filmes = n()) %>%
  filter(filmes > 100) %>%
  select(n_genres) %>%
  unique()

ts = rbind()
for (i in sort(genres$n_genres)) {
  t = bstrap_rating_by_genre(movies_ratings, i, r, sprintf("%02d gêneros", i), mean, probs)
  ts = rbind(ts, t)
}
df = data.frame(ts)

chart_ics(df, row.names(df), "IC das Avaliações dos Filmes baseado na Quantidade de Gêneros")
```

Parece que o IC da avaliação para filmes com 07 gêneros é maior que todas as outras avaliações. Uma razão para isto ter acontecido não existe apenas olhando para os dados utilizados neste relatório. Um maior estudo é necessário.

A média dos Filmes com a pior avaliação podem ser filmes com apenas um gênero, apenas olhando para o gráfico não é possível afirmar isso, aparentemente existe um intervalo que se sobrepões entre filmes com 1 gênero, e filmes com 6 gêneros.

```{r fig.width=10}
t1 = bstrap_rating_by_genre(movies_ratings, 1, r, "01 gêneros", mean, probs)
t2 = bstrap_rating_by_genre(movies_ratings, 6, r, "06 gêneros", mean, probs)

df = data.frame(rbind(t1, t2))
df$medidas = row.names(df)

chart_ics(df, df$medidas, "IC das Avaliações dos Filmes baseado na Quantidade de Gêneros")
```


Como as duas avaliações estão muito próximas, podemos calcular um intervalo de confiança com base na diferença entre as médias. Esses ICs podem ser calculados em dois cenários basicamente, quando a diferença é Pareada, e quando não é pareada.

 - Ela é **PAREADA** quando em uma mesma entidade você calcula duas medidas. Por exemplo: Comparar o **número de mulheres** que assistem filmes de terror, e o **número de homens** que assistem filmes de terros. Neste caso a entidade **filme de terror** é a mesma, entretanto a medidade difere.
 
 - Já **NÃO PAREADA** se refere a diferentes entidades mas a mesma medida. Por exemplo: Comparar a AVALIAÇÃO (uma medida) para filmes com 5 gêneros e filmes com 6 gêneros.

O nosso caso é **não pareada** pois estamos comparando a **avaliação** entre filmes com 1 e 6 gêneros (duas entidades).

```{r fig.width=10}
ratings = movies_ratings %>%
  filter(n_genres == 1 | n_genres == 6,
         !is.na(rating))

b.diff.means = bootstrap2(data = ratings$rating, 
                          treatment = ratings$n_genres, 
                          mean)

means.diff = CI.percentile(b.diff.means, probs)

data.frame(means.diff) %>% 
  ggplot(aes(x = "Diferença", ymin = X2.5., ymax = X97.5.)) + 
  geom_errorbar(width = .2) + 
  geom_hline(yintercept = 0, colour = "darkorange")
```

Como a diferença não corta o zero, podemos afirmar que **sim** os filmes com apenas um gênero tiveram a pior avaliação nestes dados. Em um contexto d 95% de confiabilidade